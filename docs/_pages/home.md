---
layout: splash
permalink: /
hidden: true
header:
  overlay_color: "#5e616c"
  overlay_image: /assets/images/grasp-anything-teaser.png
  actions:
    - label: "<i class='fas fa-download'></i> Download now"
      url: "/docs/introduction/"
excerpt: >
  Large-scale Grasp Dataset from Foundation Models<br />
  <!--small><a href="https://github.com/andvg3/Grasp-Anything">Latest release (TBD)</a></small-->
feature_row:
  - image_path: /assets/images/homepage-num-objects.png
    alt: "diversed"
    title: "Diversed objects"
    excerpt: "Grasp-Anything outperforms other datasets in terms of object diversity."
    url: "/docs/introduction/"
    btn_class: "btn--primary"
    btn_label: "Learn more"
  - image_path: /assets/images/homepage-zero-shot.jpg
    alt: "zero shot"
    title: "Zero shot learning"
    excerpt: "Our dataset improves in about 9-29% over other datasets.."
    url: "/docs/layouts/"
    btn_class: "btn--primary"
    btn_label: "Learn more"
  - image_path: /assets/images/homepage-lang-driven-demo.png
    alt: "language-driven grasp"
    title: "Language-driven grasp detection"
    excerpt: "Our dataset also enables the grasping of objects following natural language instructions."
    url: "/docs/introduction/"
    btn_class: "btn--primary"
    btn_label: "Learn more"     
---

{% include feature_row %}