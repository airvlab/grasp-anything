---
title: "Grasp-Anything-6D"
permalink: /docs/grasp-anything-6d/
excerpt: "Overview of Grasp-Anything-6D."
redirect_from:
  - /theme-setup/
toc: true
---

Built upon Grasp-Anything [[1]](#references), Grasp-Anything-6D [[2]](#references) is a large-scale dataset for the language-driven 6-DoF grasp detection task with **1M** point cloud scenes and more than **200M** language-associated 3D grasp poses.


## Samples
<p align="center">
  <img src="../../assets/images/grasp-anything-6d-samples.png" alt="samples" style="width: 100%;" />
</p>

## Language-driven Grasping
<p align="center">
  <img src="../../assets/images/grasp-anything-6d-methodology.png" alt="method" style="width: 100%;" />
</p>

We introduce a new language-driven 6-DoF grasping method with a new concept of negative prompt guidance.

## References
<a name="references"></a>

- [1] [An Dinh Vuong](https://andvg3.github.io/), Minh Nhat Vu, Hieu Le, Baoru Huang, Binh Huynh, Thieu Vo, Andreas Kugi, [Anh Nguyen](https://www.csc.liv.ac.uk/~anguyen/). *Grasp-anything: Large-scale grasp dataset from foundation models*. In ICRA, 2024.

- [2] [Toan Nguyen](https://scholar.google.com/citations?user=PhqGEY8AAAAJ&hl=en), Minh Nhat Vu, Baoru Huang, [An Dinh Vuong](https://andvg3.github.io/), Quan Vuong, Ngan Le, Thieu Vo, [Anh Nguyen](https://www.csc.liv.ac.uk/~anguyen/). *Language-Driven 6-DoF Grasp Detection Using Negative Prompt Guidance*. In ECCV, 2024.
